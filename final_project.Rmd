---
title: "project_19_fit20"
author: "Xiaolin Zheng, Sheng Cao, Xiangting Ye, Tianjiao Gao"
date: "4/30/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

````{r}
library(tidyverse)
library(lubridate)
library(sf)
library(rnaturalearthdata)
library(rnaturalearth)
library(munsell)
library(patchwork)
library(tidymodels)
library(factoextra)
library(corrplot)
```

# Part I. Data cleaning

```{r}
# load the data
whs2019 <- read_csv("2019.csv")
whs2020 <- read_csv("2020.csv")
covid2020 <- read_csv("OxCGRT_withnotes_2020.csv")
```

```{r}
# Data cleaning for whs2019 dataset
  
  # Clean the variable names
  whs2019 <- whs2019 %>%
  janitor::clean_names()

  # Select the variables
  whs2019 <- whs2019 %>%
    select(country_name, regional_indicator, ladder_score, logged_gdp_per_capita, social_support, healthy_life_expectancy, freedom_to_make_life_choices, generosity, perceptions_of_corruption) %>%
    rename("happiness" = "ladder_score")
  
  # Delete the missing values
  whs2019 <- whs2019 %>%
    na.omit()

#write.csv(whs2019, file = "whs2019_update.csv")
```

```{r}
# Data cleaning for whs2020 dataset
  
  # Clean the variable names
  whs2020 <- whs2020 %>%
  janitor::clean_names()

  # Select the variables
  whs2020 <- whs2020 %>%
    select(country_name, regional_indicator, logged_gdp_per_capita, social_support, healthy_life_expectancy, freedom_to_make_life_choices, generosity, perceptions_of_corruption) 

  # Delete the missing values
  whs2020 <- whs2020 %>%
    na.omit()
  
```

```{r}
# Data cleaning for covid2020 dataset

  # clean the data variable name
  covid2020 <- covid2020 %>%
    janitor::clean_names()
  
  # select and rename variables
  covid2020 <- covid2020 %>%
    select(c("country_name", "country_code", "region_name", "stringency_index_for_display", "government_response_index_for_display", "containment_health_index_for_display", "economic_support_index_for_display")) %>%
    rename(
      "SI" = "stringency_index_for_display",
      "GRI" = "government_response_index_for_display",
      "CHI" = "containment_health_index_for_display",
      "ESI" = "economic_support_index_for_display"
        )
  
  # group by country
  covid2020 <- covid2020 %>%
    group_by(country_name, country_code) %>%
    summarize(
      SI = mean(SI, na.rm = TRUE),
      GRI = mean(GRI, na.rm = TRUE),
      CHI = mean(CHI, na.rm = TRUE),
      ESI = mean(ESI, na.rm = TRUE)
    )
```

```{r}
# create the country code index
code_index <- covid2020 %>%
  select(country_name, country_code)
```


```{r}
# add country code column to whs2019 so that we can match whs2019 to the geometry dataset using the country code
whs2019 <- whs2019 %>%
  left_join(code_index, by = "country_name")
```

```{r}
# add country code column to whs2019 so that we can match whs2019 to the geometry dataset using the country code
whs2020 <- whs2020 %>%
  left_join(code_index, by = "country_name")
```

# Part II. Data Visualzation  

### A.

```{r}
whs2019cor <- whs2019 %>%
  select_if(is.numeric)
```

```{r}
# computing correlation matrix
cor_whs <- cor(whs2019cor)
corrplot(cor_whs, method = "color") + 
  theme_void()
```

### B.
 
```{r}
# load the world map data
world <- ne_countries(scale = "medium", returnclass = "sf")
```


```{r}
# clean the world map dataset
world_map <- world %>%
  select(admin, adm0_a3, geometry) %>%
  rename(
    "country_name" = "admin",
    "country_code" = "adm0_a3"
  ) %>%
  st_transform(crs = 4326)
```


```{r}
# match two dataset
whs2019_geometry <- left_join(world_map, whs2019, by = "country_code") %>%
  na.omit()
```


```{r}
# draw the hapiness index map
ggplot(whs2019_geometry) +
  geom_sf(aes(fill = happiness)) +
  scale_fill_distiller(palette = "YlOrBr") +
  theme_void() +
  labs(
    title = "Rich countries have higher level of happiness",
    subtitle = "2019",
    caption = "World Hapiness Report 2019"
  )

```



# Part III. Choosing the best model using the data of world happiness report of 2019


```{r split the  data, message=FALSE, warning=FALSE}
# set the seed
set.seed(20211101)

# split the data
split <- initial_split(whs2019)
whs19_train <- training(split)
whs19_test <- testing(split)
```

```{r set up folds, message=FALSE, warning=FALSE}
# set the seed
set.seed(20211101)

# set up v-fold cross-validation
folds <- vfold_cv(data = whs19_train, v = 10)
```

```{r create a recipe }
# create a recipe
whs_rec <- 
  recipe(happiness ~ ., data = whs19_train) %>%
  # select all numeric variables and remove covid-related variables
  step_rm(country_name, regional_indicator, country_code) %>%
  
  # center and scale predictors
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors()) %>%
  prep()
  
# see the engineered training data
bake(prep(whs_rec, data = whs19_train), new_data = whs19_train)
```

### Model A. Random Forest

```{r set up for the model, message=FALSE, warning=FALSE}
# number of features in the dataset
n_features <- length(setdiff(names(whs19_train), "happiness"))

# create hyperparameter grid for random forest model
rf_grid <- expand.grid(
  mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
  min_n = c(1, 3, 5, 10)
)
```

```{r create a Random Forest model, message=FALSE, warning=FALSE}
# create a model
rf_mod <- rand_forest(
  mtry = tune(),
  trees = n_features * 10,
  min_n = tune()
) %>%
  set_engine("ranger") %>%
  set_mode("regression")
```

```{r create the workflow for Random Forest model, message=FALSE, warning=FALSE}
# create a workflow
rf_wf <- workflow() %>%
  add_recipe(whs_rec) %>%
  add_model(rf_mod)
```

```{r fit the Random Forest model, message=FALSE, warning=FALSE}
# fit the model
rf_cv <- rf_wf %>%
  tune_grid(
    resamples = folds,
    grid = rf_grid
  )
```

```{r select the best parameter for Random Forest model, message=FALSE, warning=FALSE}
# select the best model based on the "rmse" metric
rf_best <- rf_cv %>%
  select_best(metric = "rmse")
```

```{r update the workflow for the Random Forest model, message=FALSE, warning=FALSE}
# use the best model to update the workflow
rf_final <- finalize_workflow(
  rf_wf,
  parameters = rf_best
)
```

```{r fit the resample using the best parameter, message=FALSE, warning=FALSE}
# use the best parameter to fit the resamples
rf_fit <- rf_final %>%
  fit_resamples(
    resamples = folds) %>%
  collect_metrics() %>%
  filter(.metric == "rmse")
  
 
# select the MSE for each resample
print(rf_fit) 
```

```{r fit the entire training data for Random Forest model, message=FALSE, warning=FALSE}
# use the best parameter of Random Forest model to fit the entire training data
rf_fittrain <-
  rf_wf %>%
  finalize_workflow(parameters = rf_best) %>%
  fit(data = whs19_train) 
```

```{r make predictions using testing data, message=FALSE, warning=FALSE}
# make predictions with the testing data
pred_testrf <-
  bind_cols(
    whs19_test,
    predict(rf_fittrain, new_data = whs19_test)
  )

select(pred_testrf, .pred, happiness)
```

```{r calculate the RMSE, message=FALSE, warning=FALSE}
# calculate the RMSE on the testing data
rmse(data = pred_testrf, truth = happiness, estimate = .pred)
```

### Model B: Lasso

```{r}
# set the tunning grid for lasso model
lasso_grid <- grid_regular(penalty(), levels = 10)
```

```{r}
# create the lasso model
lasso_mod <- linear_reg(
  penalty = tune(),
  mixture = 1
  ) %>%
  set_engine("glmnet")
```


```{r}
# create the workflow for lasso model
lasso_wf <- workflow() %>%
  add_recipe(whs_rec) %>%
  add_model(lasso_mod)
```

```{r}
# fit the resamples
lasso_cv <- lasso_wf %>%
  tune_grid(
    resample = folds,
    grid = lasso_grid
    )
```

```{r}
# choose the best parameter
lasso_best <- lasso_cv %>%
  select_best(metric = "rmse")
```


```{r}
# use the best model to update the workflow
lasso_final <- finalize_workflow(
  lasso_wf,
  parameters = lasso_best
)
```


```{r}
# use the best parameter to fit the  whole training set
lasso_final2 <- lasso_wf %>%
  finalize_workflow(parameters = lasso_best) %>%
  fit(data = whs19_train)
```


```{r}
# using the best model to fit the whole testing dataset 
pred_testlasso <-
  bind_cols(
    whs19_test,
    predict(lasso_final2, new_data = whs19_test)
  )
```


```{r}
# calculate the rmse
select(pred_testlasso, .pred, happiness)

rmse(data = pred_testlasso, truth = happiness, estimate = .pred)
```

As Random Forest Model returns lower rmse, we choose it as our machine learning model to predict the happiness in 2020 for each country.

# Part IV. Predict
 
```{r implement using Random Forest model , message=FALSE, warning=FALSE}
# make predictions for 2020 happiness score
happi_2020 <- bind_cols(
    whs2020,
    predict(object = rf_fittrain, new_data = whs2020)
  )

happi_2020 <- happi_2020 %>%
  rename("happiness" = ".pred")
```

